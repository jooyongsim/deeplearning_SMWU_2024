{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 숙명여자대학교 Deep Learning 2024 수업 Lab 9: Self-Supervised"
      ],
      "metadata": {
        "id": "zXTccWVgU_ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-supervised Learning with TensorFlow\n",
        "\n",
        "\n",
        "## Pretext Task - Rotation\n",
        "\n",
        "### RotNet\n",
        "Hypothesis: a model could recognize the correct rotation of an object only if it has the “visual common sense” of what the object should look like self-supervised learning by rotating the entire input images. The model learns to predict which rotation is applied (4-way classification)\n",
        "\n",
        "### Supervised vs Self-supervised\n",
        "The accuracy gap between the RotNet based model and the fully supervised Network-In-Network (NIN) model is very small, only 1.64% points\n",
        "We do not need data labels to train the RotNet based model but achieved similar accuracy with that of the model which used data labels for training"
      ],
      "metadata": {
        "id": "0rvW_VT_AF9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library and Load MNIST"
      ],
      "metadata": {
        "id": "pLFfmF9J2qmG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnaoUQvCuiPT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use 10000 self-supervision data, 1000 downstream task data, and 300 test data"
      ],
      "metadata": {
        "id": "r6mqwpx5K1hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "XX_train = X_train[10000:11000]\n",
        "YY_train = Y_train[10000:11000]\n",
        "X_train = X_train[:10000]\n",
        "Y_train = Y_train[:10000]\n",
        "XX_test = X_test[300:600]\n",
        "YY_test = Y_test[300:600]\n",
        "X_test = X_test[:300]\n",
        "Y_test = Y_test[:300]"
      ],
      "metadata": {
        "id": "ZpFvk-EamA1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "id": "KyjENdDdXjyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('shape of x_train:', X_train.shape)\n",
        "print('shape of y_train:', Y_train.shape)\n",
        "print('shape of xx_train:', XX_train.shape)\n",
        "print('shape of yy_train:', YY_train.shape)\n",
        "print('shape of x_test:', X_test.shape)\n",
        "print('shape of y_test:', Y_test.shape)\n",
        "print('shape of xx_test:', XX_test.shape)\n",
        "print('shape of yy_test:', YY_test.shape)"
      ],
      "metadata": {
        "id": "XVbUx-QpG3m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build RotNet for Pretext Task\n",
        "\n",
        "### Dataset for Pretext Task (Rotation)\n",
        "Need to generate rotated images and their labels to train the model for pretext task\n",
        "\n",
        "[1, 0, 0, 0]: 0 degree rotation\n",
        "\n",
        "[0, 1, 0, 0]; 90 degree rotation\n",
        "\n",
        "[0, 0, 1, 0]: 180 degree rotation\n",
        "\n",
        "[0, 0, 0, 1]; 270 degree rotation"
      ],
      "metadata": {
        "id": "VPgGapDWVuMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = X_train.shape[0]\n",
        "X_rotate = np.zeros(shape = (n_samples*4,\n",
        "                             X_train.shape[1],\n",
        "                             X_train.shape[2]))\n",
        "Y_rotate = np.zeros(shape = (n_samples*4, 4))\n",
        "\n",
        "for i in range(n_samples):\n",
        "    img = X_train[i]\n",
        "    X_rotate[4*i-4] = img\n",
        "    Y_rotate[4*i-4] = tf.one_hot([0], depth = 4)\n",
        "\n",
        "    # 90 degrees rotation\n",
        "    X_rotate[4*i-3] = np.rot90(img, k = 1)\n",
        "    Y_rotate[4*i-3] = tf.one_hot([1], depth = 4)\n",
        "\n",
        "    # 180 degrees rotation\n",
        "    X_rotate[4*i-2] = np.rot90(img, k = 2)\n",
        "    Y_rotate[4*i-2] = tf.one_hot([2], depth = 4)\n",
        "\n",
        "    # 270 degrees rotation\n",
        "    X_rotate[4*i-1] = np.rot90(img, k = 3)\n",
        "    Y_rotate[4*i-1] = tf.one_hot([3], depth = 4)"
      ],
      "metadata": {
        "id": "AtI01mgr_95f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Dataset for Pretext Task (Rotation)"
      ],
      "metadata": {
        "id": "t5SSCuO18-Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize = (10, 10))\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_rotate[12], cmap = 'gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_rotate[13], cmap = 'gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_rotate[14], cmap = 'gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_rotate[15], cmap = 'gray')\n",
        "plt.axis('off')\n",
        "\n",
        "X_rotate = X_rotate.reshape(-1,28,28,1)\n"
      ],
      "metadata": {
        "id": "AgCf_1fj88iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model for Pretext Task (Rotation)\n",
        "\n"
      ],
      "metadata": {
        "id": "4Agrk6BQbmSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretext = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64,\n",
        "                           kernel_size = (3,3),\n",
        "                           strides = (2,2),\n",
        "                           activation = 'relu',\n",
        "                           padding = 'SAME',\n",
        "                           input_shape = (28, 28, 1)),\n",
        "\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters = 32,\n",
        "                           kernel_size = (3,3),\n",
        "                           strides = (1,1),\n",
        "                           activation = 'relu',\n",
        "                           padding = 'SAME',\n",
        "                           input_shape = (7, 7, 64)),\n",
        "\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters = 16,\n",
        "                           kernel_size = (3,3),\n",
        "                           strides = (2,2),\n",
        "                           activation = 'relu',\n",
        "                           padding = 'SAME',\n",
        "                           input_shape = (3, 3, 32)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(units = 4, activation = 'softmax')\n",
        "\n",
        "])\n",
        "model_pretext.summary()"
      ],
      "metadata": {
        "id": "zAPTkRthk7uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model for the pretext task\n"
      ],
      "metadata": {
        "id": "ywuAV_D83bQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretext.compile(optimizer = 'adam',\n",
        "                      loss = 'categorical_crossentropy',\n",
        "                      metrics = 'accuracy')\n",
        "\n",
        "model_pretext.fit(X_rotate,\n",
        "                  Y_rotate,\n",
        "                  batch_size = 192,\n",
        "                  epochs = 50,\n",
        "                  verbose = 2,\n",
        "                  shuffle = False)"
      ],
      "metadata": {
        "id": "s8MvxukJk52T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Build Downstream Task (MNIST Image Classification)\n",
        "Freezing trained parameters to transfer them for the downstream task\n"
      ],
      "metadata": {
        "id": "-_NJhDd2oAvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretext.trainable = False\n"
      ],
      "metadata": {
        "id": "DeGEj2V9t2z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "vnhOM1XpoFjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XX_train = XX_train.reshape(-1,28,28,1)\n",
        "XX_test = XX_test.reshape(-1,28,28,1)\n",
        "YY_train = tf.one_hot(YY_train, 10, on_value = 1.0, off_value = 0.0)\n",
        "YY_test = tf.one_hot(YY_test, 10, on_value = 1.0, off_value = 0.0)"
      ],
      "metadata": {
        "id": "S9bZ9Np2oCUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        "### Model: two convolution layers and one fully connected layer\n",
        "\n",
        "Two convolution layers are transferred from the model for the pretext task\n",
        "\n",
        "Single fully connected layer is trained only"
      ],
      "metadata": {
        "id": "rGokNqw8rXa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretext.get_layer(index = 0), model_pretext.get_layer(index = 1), \\\n",
        "model_pretext.get_layer(index = 2), model_pretext.get_layer(index = 3)"
      ],
      "metadata": {
        "id": "3wv8CUDkYDa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_downstream = tf.keras.models.Sequential([\n",
        "    model_pretext.get_layer(index = 0),\n",
        "    model_pretext.get_layer(index = 1),\n",
        "    model_pretext.get_layer(index = 2),\n",
        "    model_pretext.get_layer(index = 3),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model_downstream.summary()"
      ],
      "metadata": {
        "id": "tIlHOvK_oKd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only use (1, 5, 6) digits to visualize latent space in 2-D"
      ],
      "metadata": {
        "id": "AqXZ4yZkrllO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_downstream.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001,momentum = 0.9),\n",
        "                         loss = 'categorical_crossentropy',\n",
        "                         metrics = 'accuracy')\n",
        "\n",
        "model_downstream.fit(XX_train,\n",
        "                     YY_train,\n",
        "                     batch_size = 64,\n",
        "                     validation_split = 0.2,\n",
        "                     epochs = 50,\n",
        "                     verbose = 2,\n",
        "                     callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 7))"
      ],
      "metadata": {
        "id": "Hyr7DvivrWPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downstream Task Trained Result (Image Classification Result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vsNkhupYrq-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "id": "60Bg452RY8Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = ['0', '1', '2', '3', '4', '5','6', '7', '8', '9']\n",
        "idx = 9\n",
        "img = XX_train[idx].reshape(-1,28,28,1)\n",
        "label = YY_train[idx]\n",
        "predict = model_downstream.predict(img)\n",
        "mypred = np.argmax(predict, axis = 1)\n",
        "\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img.reshape(28, 28), 'gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.stem(predict[0])\n",
        "plt.show()\n",
        "\n",
        "print('Prediction : {}'.format(name[mypred[0]]))"
      ],
      "metadata": {
        "id": "y3KpBQJ6rruj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised Model for Comparison\n",
        "Convolution Neural Networks for MNIST image classification\n",
        "Model: Same model architecture with the model for the downstream task\n",
        "The number of total parameter is the same with the model for the downstream task, but is has zero non-trainable parameters"
      ],
      "metadata": {
        "id": "_gIGym-LrwKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sup = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 64,\n",
        "                           kernel_size = (3,3),\n",
        "                           strides = (2,2),\n",
        "                           activation = 'relu',\n",
        "                           padding = 'SAME',\n",
        "                           input_shape = (28, 28, 1)),\n",
        "\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters = 32,\n",
        "                           kernel_size = (3,3),\n",
        "                           strides = (1,1),\n",
        "                           activation = 'relu',\n",
        "                           padding = 'SAME',\n",
        "                           input_shape = (7, 7, 64)),\n",
        "\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2, 2),\n",
        "                              strides = (2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "\n",
        "])\n",
        "model_sup.summary()"
      ],
      "metadata": {
        "id": "m0jNGhd4J3LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sup.trainable = False\n",
        "model_rand = tf.keras.models.Sequential([\n",
        "    model_sup.get_layer(index = 0),\n",
        "    model_sup.get_layer(index = 1),\n",
        "    model_sup.get_layer(index = 2),\n",
        "    model_sup.get_layer(index = 3),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model_rand.summary()"
      ],
      "metadata": {
        "id": "WkmGS5leaoMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sup.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001,momentum = 0.9),\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics = 'accuracy')\n",
        "model_sup.fit(XX_train,\n",
        "              YY_train,\n",
        "              batch_size = 32,\n",
        "              validation_split = 0.2,\n",
        "              epochs = 50,\n",
        "              verbose = 2,\n",
        "              callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 7))"
      ],
      "metadata": {
        "id": "3x2EOWtqKpSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rand.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001,momentum = 0.9),\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics = 'accuracy')\n",
        "model_rand.fit(XX_train,\n",
        "              YY_train,\n",
        "              batch_size = 32,\n",
        "              validation_split = 0.2,\n",
        "              epochs = 50,\n",
        "              verbose = 2,\n",
        "              callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', patience = 7))"
      ],
      "metadata": {
        "id": "YUAZvy9ka2UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Self-supervised Learning and Supervised Learning\n",
        "\n",
        "### Pretext Task\n",
        "Input data: 10,000 MNIST images without labels\n",
        "\n",
        "### Downstream Task and Supervised Learning (for performance comparison)\n",
        "\n",
        "Training data: 1,000 MNIST images with labels\n",
        "Test data: 300 MNIST images with labels\n",
        "\n",
        "### Key concepts\n",
        "For transfer learning, we used to train networks like VGG 16 with large image dataset with labels such as ImageNet\n",
        "\n",
        "With self-supervised learning, we train such networks with unlabeled image datasets which have larger number of data than labeled image datasets have and perform transfer learning\n",
        "\n",
        "Comparing downstream task performance with that of supervised learning is equal to comparing the performance of (self-supervised) transfer learning and supervised learning performance"
      ],
      "metadata": {
        "id": "1BTgXUkq4Nfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_self = model_rand.evaluate(XX_test,YY_test,batch_size = 64,verbose = 2)\n",
        "\n",
        "print(\"\")\n",
        "print('Self-supervised Learning Accuracy on Test Data:  {:.2f}%'.format(test_self[1]*100))"
      ],
      "metadata": {
        "id": "G9v97Ahha91d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_self = model_downstream.evaluate(XX_test,YY_test,batch_size = 64,verbose = 2)\n",
        "\n",
        "print(\"\")\n",
        "print('Self-supervised Learning Accuracy on Test Data:  {:.2f}%'.format(test_self[1]*100))"
      ],
      "metadata": {
        "id": "ofkZuBth4Z2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sup = model_sup.evaluate(XX_test,YY_test,batch_size = 64, verbose = 2)\n",
        "\n",
        "print(\"\")\n",
        "print('Supervised Learning Accuracy on Test Data:  {:.2f}%'.format(test_sup[1]*100))"
      ],
      "metadata": {
        "id": "5bjSNXS-4bvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}