{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSfJ_MnIZJsb"
      },
      "source": [
        "# 숙명여자대학교 기계시스템학부 딥러닝 2024: Lab2\n",
        "\n",
        "## Topic: **nn Module Autoencoder**\n",
        "## (강사: 심주용)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8un1qhReBNK"
      },
      "source": [
        "# Barebore Pytorch - Review\n",
        "## Weight Initialization\n",
        "\n",
        "Weight initialization is crucial in deep learning as it can significantly impact the model's convergence and performance. This tutorial covers the process of initializing weights and biases in a neural network using PyTorch, focusing on a three-layer fully connected network trained on the FashionMNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCfPHO14fhlp"
      },
      "source": [
        "\n",
        "### Initializing Weights and Biases\n",
        "In the NeuralNetwork class, we define the layers of the neural network with custom parameters using nn.Parameter. Each layer has its weights and biases, represented as matrices and vectors, respectively. We use PyTorch's torch.Tensor to define these parameters.\n",
        "\n",
        "### Kaiming (He) Initialization\n",
        "We apply Kaiming (or He) initialization to the weights using nn.init.kaiming_uniform_. This method is particularly suited for layers followed by ReLU activation functions, as it considers the nonlinearity of the activations. The initialization helps prevent vanishing or exploding gradients during training, promoting faster convergence and improved performance.\n",
        "\n",
        "Kaiming initialization sets the tensor values uniformly in the range\n",
        "[−a,a], where a=5 . This range is derived from the number of input and output units in the tensor, ensuring that the variance remains constant across layers.\n",
        "\n",
        "### Zero Initialization for Biases\n",
        "The biases are initialized to zero using nn.init.constant_. This is a common practice as it starts the neurons with an output of zero before adjusting during training, allowing the network to learn the bias for each neuron.\n",
        "\n",
        "### Forward Pass\n",
        "In the forward method, the input tensor is flattened and passed through the linear layers with ReLU activations, except for the last layer, which directly outputs the logits. This method defines how the data flows through the network, utilizing the initialized weights and biases.\n",
        "\n",
        "### Training and Testing\n",
        "The model is then compiled, trained, and evaluated. During training, the weights and biases are automatically adjusted through backpropagation. The weight initialization plays a critical role in ensuring that these adjustments lead to effective learning.\n",
        "\n",
        "### Outlook\n",
        "Proper weight initialization, like Kaiming initialization used here, is essential for training deep neural networks efficiently. It helps in maintaining a stable gradient flow across layers, leading to faster and more reliable convergence during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lywQzQXeBdr",
        "outputId": "f2c59237-3530-4012-f794-609d087d6a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork()\n",
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.266513  [    0/60000]\n",
            "loss: 0.514421  [ 6400/60000]\n",
            "loss: 0.408110  [12800/60000]\n",
            "loss: 0.459795  [19200/60000]\n",
            "loss: 0.432227  [25600/60000]\n",
            "loss: 0.412075  [32000/60000]\n",
            "loss: 0.349046  [38400/60000]\n",
            "loss: 0.548770  [44800/60000]\n",
            "loss: 0.423509  [51200/60000]\n",
            "loss: 0.461233  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.416501 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.249283  [    0/60000]\n",
            "loss: 0.337073  [ 6400/60000]\n",
            "loss: 0.280285  [12800/60000]\n",
            "loss: 0.386535  [19200/60000]\n",
            "loss: 0.421984  [25600/60000]\n",
            "loss: 0.367151  [32000/60000]\n",
            "loss: 0.343159  [38400/60000]\n",
            "loss: 0.497576  [44800/60000]\n",
            "loss: 0.363690  [51200/60000]\n",
            "loss: 0.413945  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.392135 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.202920  [    0/60000]\n",
            "loss: 0.314568  [ 6400/60000]\n",
            "loss: 0.245939  [12800/60000]\n",
            "loss: 0.370692  [19200/60000]\n",
            "loss: 0.366005  [25600/60000]\n",
            "loss: 0.356492  [32000/60000]\n",
            "loss: 0.276950  [38400/60000]\n",
            "loss: 0.433473  [44800/60000]\n",
            "loss: 0.312002  [51200/60000]\n",
            "loss: 0.380368  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.366470 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.176348  [    0/60000]\n",
            "loss: 0.287301  [ 6400/60000]\n",
            "loss: 0.234609  [12800/60000]\n",
            "loss: 0.282410  [19200/60000]\n",
            "loss: 0.331092  [25600/60000]\n",
            "loss: 0.330698  [32000/60000]\n",
            "loss: 0.268119  [38400/60000]\n",
            "loss: 0.412648  [44800/60000]\n",
            "loss: 0.266829  [51200/60000]\n",
            "loss: 0.385995  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.365120 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.212655  [    0/60000]\n",
            "loss: 0.250789  [ 6400/60000]\n",
            "loss: 0.216922  [12800/60000]\n",
            "loss: 0.251182  [19200/60000]\n",
            "loss: 0.324407  [25600/60000]\n",
            "loss: 0.287800  [32000/60000]\n",
            "loss: 0.223120  [38400/60000]\n",
            "loss: 0.351441  [44800/60000]\n",
            "loss: 0.252123  [51200/60000]\n",
            "loss: 0.294193  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.364121 \n",
            "\n",
            "Done!\n",
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 28*28\n",
        "        self.hidden_size = 512\n",
        "        self.output_size = 10\n",
        "\n",
        "        # Initialize weights and biases for linear layers\n",
        "        self.weight1 = nn.Parameter(torch.Tensor(self.hidden_size, self.input_size))\n",
        "        self.bias1 = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.weight2 = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
        "        self.bias2 = nn.Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.weight3 = nn.Parameter(torch.Tensor(self.output_size, self.hidden_size))\n",
        "        self.bias3 = nn.Parameter(torch.Tensor(self.output_size))\n",
        "\n",
        "        # Kaiming initialization for weights\n",
        "        nn.init.kaiming_uniform_(self.weight1, nonlinearity='relu')\n",
        "        nn.init.kaiming_uniform_(self.weight2, nonlinearity='relu')\n",
        "        nn.init.kaiming_uniform_(self.weight3, nonlinearity='relu')\n",
        "\n",
        "        # Initialize biases to zero\n",
        "        nn.init.constant_(self.bias1, 0)\n",
        "        nn.init.constant_(self.bias2, 0)\n",
        "        nn.init.constant_(self.bias3, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input tensor\n",
        "        x = x.view(-1, self.input_size)\n",
        "\n",
        "        # Apply the first linear layer and ReLU\n",
        "        x = F.relu(F.linear(x, self.weight1, self.bias1))\n",
        "        # Apply the second linear layer and ReLU\n",
        "        x = F.relu(F.linear(x, self.weight2, self.bias2))\n",
        "        # Apply the third linear layer\n",
        "        logits = F.linear(x, self.weight3, self.bias3)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Assuming 'device' is defined elsewhere, e.g.,\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = NeuralNetwork().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the training loop\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Define the testing loop\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBkD4QNdrMb"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnZenImXee0w"
      },
      "source": [
        "## Data Loading and Preparation\n",
        "In this part, we load the MNIST dataset, which consists of handwritten digits, and prepare it for training and testing. We use PyTorch's datasets and transforms modules to download and transform the data into a suitable format. The data is filtered to include only the digits 1, 5, and 6. Each image is converted to a tensor and flattened since our neural network will use fully connected layers. Normalization is applied to the images by scaling pixel values to the range [0, 1]. This process helps in reducing the complexity of the model's calculations and improves the training efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngEQ9ss1drfR",
        "outputId": "3f79cadd-3b7d-42db-cc07-df89f6418348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 79375225.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 21623651.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 21623377.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5601449.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "The number of training images: 18081, shape: torch.Size([18081, 28, 28])\n",
            "The number of testing images: 2985, shape: torch.Size([2985, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])\n",
        "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Select only digits 1, 5, 6 for training and testing\n",
        "train_mask = (mnist.targets == 1) | (mnist.targets == 5) | (mnist.targets == 6)\n",
        "test_mask = (mnist_test.targets == 1) | (mnist_test.targets == 5) | (mnist_test.targets == 6)\n",
        "\n",
        "train_imgs = mnist.data[train_mask].float() / 255\n",
        "train_labels = mnist.targets[train_mask]\n",
        "test_imgs = mnist_test.data[test_mask].float() / 255\n",
        "test_labels = mnist_test.targets[test_mask]\n",
        "\n",
        "print(f\"The number of training images: {train_imgs.shape[0]}, shape: {train_imgs.shape}\")\n",
        "print(f\"The number of testing images: {test_imgs.shape[0]}, shape: {test_imgs.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqaArc2WexQN"
      },
      "source": [
        "## Define Model Structure and Training\n",
        "Here, we define the structure of our autoencoder, which consists of an encoder and a decoder. The encoder compresses the input image into a lower-dimensional latent space, while the decoder reconstructs the image from the latent space representation. We use fully connected layers (nn.Linear) with ReLU activations for both parts. The autoencoder class combines these two components. We then compile the model using the Adam optimizer and mean squared error loss function, which is common for reconstruction tasks. The training process involves feeding the input data through the autoencoder to generate reconstructed images and updating the model weights to minimize the reconstruction error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk4QsdAbep95",
        "outputId": "4bfbb917-b834-4a37-a066-1117ca57aed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([28, 28])) that is different to the input size (torch.Size([1, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Encoder structure\n",
        "encoder = nn.Sequential(\n",
        "    nn.Linear(28*28, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 300),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(300, 2)\n",
        ")\n",
        "\n",
        "# Decoder structure\n",
        "decoder = nn.Sequential(\n",
        "    nn.Linear(2, 300),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(300, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 28*28)\n",
        ")\n",
        "\n",
        "# Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.input_size = 28\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size**2)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = x.view(-1,self.input_size,self.input_size)\n",
        "        return x\n",
        "\n",
        "autoencoder = Autoencoder()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Train model\n",
        "for epoch in range(10):\n",
        "    for data in train_imgs:\n",
        "        optimizer.zero_grad()\n",
        "        output = autoencoder(data)\n",
        "        loss = criterion(output, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5H7VFPiezxy"
      },
      "source": [
        "## Evaluate and Visualize Results\n",
        "After training, we evaluate the model's performance by visualizing how well it can separate the different digits in the latent space. We randomly select a subset of the test images, pass them through the encoder to obtain their latent representations, and plot these in a scatter plot. Each digit type is represented with a different color. This visualization helps in understanding the quality of the learned representations and how well the model can distinguish between different digits based on their latent features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eKwral-etRA"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    idx = np.random.randint(0, len(test_labels), 500)\n",
        "    test_x = test_imgs[idx]\n",
        "    test_y = test_labels[idx]\n",
        "    test_latent = autoencoder.encoder(test_x)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(test_latent[:, 0][test_y == 1], test_latent[:, 1][test_y == 1], label='1')\n",
        "    plt.scatter(test_latent[:, 0][test_y == 5], test_latent[:, 1][test_y == 5], label='5')\n",
        "    plt.scatter(test_latent[:, 0][test_y == 6], test_latent[:, 1][test_y == 6], label='6')\n",
        "    plt.title('Latent Space')\n",
        "    plt.xlabel('Z1')\n",
        "    plt.ylabel('Z2')\n",
        "    plt.legend()\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bclABvLne2_-"
      },
      "source": [
        "## Generate New Data and Visualize\n",
        "In the final part, we demonstrate the generative capability of the autoencoder. We manually define new points in the latent space and use the decoder to generate images from these points. This shows how the decoder part of the autoencoder can create new images that resemble the training data, based on the learned features in the latent space. The resulting images are then plotted alongside the latent space to show the correlation between the latent representation and the reconstructed images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60oEtkQheu0l"
      },
      "outputs": [],
      "source": [
        "# Generate new data\n",
        "new_data = torch.tensor([[1.0, 0.0]])\n",
        "with torch.no_grad():\n",
        "    fake_image = autoencoder.decoder(new_data)\n",
        "\n",
        "    plt.figure(figsize=(13, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(test_latent[:, 0][test_y == 1], test_latent[:, 1][test_y == 1], label='1')\n",
        "    plt.scatter(test_latent[:, 0][test_y == 5], test_latent[:, 1][test_y == 5], label='5')\n",
        "    plt.scatter(test_latent[:, 0][test_y == 6], test_latent[:, 1][test_y == 6], label='6')\n",
        "    plt.scatter(new_data[:, 0], new_data[:, 1], c='k', marker='o', s=200, label='new data')\n",
        "    plt.title('Latent Space')\n",
        "    plt.xlabel('Z1')\n",
        "    plt.ylabel('Z2')\n",
        "    plt.legend(loc=2)\n",
        "    plt.axis('equal')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(fake_image.reshape(28, 28), cmap='gray')\n",
        "    plt.title('Generated Fake Image')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}